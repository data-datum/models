<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>23-pres.utf8</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="animate.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: inverse, center


# &lt;svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 581 512"&gt;&lt;path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/&gt;&lt;/svg&gt; Preparaci√≥n Certificaci√≥n RStudio  üöÄ&lt;br&gt; &lt;br&gt; 

## üîßModelos Cap√≠tulo 23 üíª 
&lt;br&gt; &lt;br&gt; &lt;br&gt; 

.large[Roxana N. Villafa√±e &lt;a href='http://twitter.com/data_datum'&gt;&lt;svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 512 512"&gt;&lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/&gt;&lt;/svg&gt; @data_datum&lt;/a&gt;] &lt;br&gt; 



‚ú®
&lt;br&gt; Link &lt;https://data-datum.github.io/models/models/23-pres.html#1&gt; üåü

---

background-image: url(img/text-msg.png)
background-size: cover
class: center, middle

# Generalidades del tema


---

background-image: url(img/fondo-madera.png)
background-size: cover
class: center, middle


## El objetivo de un modelo es 
## proveer un resumen de baja dimensi√≥n 
## de un conjunto de datos

    



---

# Prerrequisitos

En este cap√≠tulo usaremos el paquete modelr que tiene las funciones de modelado de R base para que funcionen naturalmente en un pipe.


```r
library(tidyverse)

library(modelr)
options(na.action = na.warn)
```

---

## Un modelo simple

Miremos el conjunto de datos simulado sim1, inclu√≠do dentro del paquete modelr. Este contiene dos variables continuas, x e y. Grafiqu√©moslas para ver como est√°n relacionadas:


```r
ggplot(sim1, aes(x, y)) +
  geom_point()
```

![](23-pres_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;


---

# Un mal modelo

Se sobreentiende que un buen modelo es aquel que est√° "cerca" de los datos

![](23-pres_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;

---

# Un buen modelo

![Caption for the picture](img/grafico-modelos.png)



---

background-image: url(img/fondo-madera.png)
background-size: cover
class: center, middle

## Hay dos partes en un modelo:

### 1. Definir una familia de modelos que expresa un patr√≥n que se quiere capturar. Debe ser preciso y gen√©rico. Ej; una l√≠nea recta o curva cuadr√°tica 
### 2. Generar un modelo ajustado al encontrar un modelo de la familia que sea lo m√°s cercano a tus datos. 


---

background-image: url(img/fondo-madera.png)
background-size: cover
class: center, middle

## Un lugar f√°cil para comenzar es encontrar la distancia vertical entre cada punto y el modelo.
## La distancia es solo la diferencia entre el valor dado por el modelo (la predicci√≥n), y el valor real y en los datos (la respuesta).

---

# Primer paso

### Para calcular esta distancia, 
### transformamos nuestra familia de modelos en una funci√≥n de R. Esta funci√≥n toma los par√°metros del modelo y los datos como inputs, y retorna el valor predicho por el modelo como output:


```r
model1 &lt;- function(a, data) {
  a[1] + data$x * a[2]
}
model1(c(7, 1.5), sim1)
```

```
##  [1]  8.5  8.5  8.5 10.0 10.0 10.0 11.5 11.5 11.5 13.0 13.0 13.0 14.5 14.5 14.5
## [16] 16.0 16.0 16.0 17.5 17.5 17.5 19.0 19.0 19.0 20.5 20.5 20.5 22.0 22.0 22.0
```

---
# Distancia entre lo predicho y los valores reales. 

¬øC√≥mo las colapsamos en un √∫nico n√∫mero?

En estad√≠stica se usa la __‚Äúra√≠z del error cuadr√°tico medio‚Äù (RMSE o root-mean-squared deviation).__

Calculamos la diferencia entre los valores reales y los predichos, los elevamos al cuadrado, luego se promedian y tomamos la ra√≠z cuadrada. 


```r
measure_distance &lt;- function(mod, data) {
  diff &lt;- data$y - model1(mod, data)
  sqrt(mean(diff^2))
}
measure_distance(c(7, 1.5), sim1)
```

```
## [1] 2.665212
```

---
## Purrr
Calcular la distancia de todos los modelos definidos anteriormente. 
Necesitamos una funci√≥n auxiliar debido a que nuestra funci√≥n de distancia espera que el modelo sea un vector num√©rico de longitud 2.


```r
sim1_dist &lt;- function(a1, a2) {
  measure_distance(c(a1, a2), sim1)
}

modelos &lt;- modelos %&gt;%
  mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))
modelos
```

```
## # A tibble: 250 x 3
##         a1      a2  dist
##      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
##  1   6.91   2.55    6.03
##  2   0.642 -3.92   40.3 
##  3  28.7   -2.64   13.7 
##  4  26.9    4.42   36.4 
##  5   9.94   3.95   17.2 
##  6   1.61   3.70    8.26
##  7  32.1   -3.44   16.1 
##  8 -15.1   -0.708  35.5 
##  9 -19.9   -0.490  38.9 
## 10  11.0    0.0815  7.29
## # ‚Ä¶ with 240 more rows
```

---
### 10 mejores modelos

He coloreado los modelos usando -dist: esto es una forma f√°cil de asegurarse de que los mejores modelos (es decir, aquellos con la menor distancia) tengan los colores m√°s brillantes.


```r
ggplot(sim1, aes(x, y)) +
  geom_point(size = 2, colour = "grey30") +
  geom_abline(
    aes(intercept = a1, slope = a2, colour = -dist),
    data = filter(modelos, rank(dist) &lt;= 10)
  )
```

![](23-pres_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;



---

## Usando una grilla (1)


```r
ggplot(modelos, aes(a1, a2)) +
  geom_point(data = filter(modelos, rank(dist) &lt;= 10), size = 4, colour = "red") +
  geom_point(aes(colour = -dist))
```

![](23-pres_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

---
## Usando una grilla (2)
![](23-pres_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;

---
Cuando superpones los mejores 10 modelos en los datos originales, se ven bastante bien:


```r
ggplot(sim1, aes(x, y)) +
  geom_point(size = 2, colour = "grey30") +
  geom_abline(
    aes(intercept = a1, slope = a2, colour = -dist),
    data = filter(grid, rank(dist) &lt;= 10))
```

![](23-pres_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;

---

### Conclusi√≥n

De forma iterativa se puede hacer la cuadr√≠cula m√°s y m√°s fina hasta reducir los resultados al mejor modelo.

_Existe una forma mejor de resolver el problema:_ una herramienta de minimizaci√≥n llamada __b√∫squeda de Newton-Raphson__. La intuici√≥n detr√°s de Newton-Raphson es bastante simple: tomas un punto de partida y buscas la pendiente m√°s fuerte en torno a ese punto. Puedes bajar por esa pendiente un poco, para luego repetir el proceso varias veces, hasta que no se puede descender m√°s. __En R, esto se puede hacer con la funci√≥n optim():__


```r
best &lt;- optim(c(0, 0), measure_distance, data = sim1)
best$par
```

```
## [1] 4.222248 2.051204
```

---


```r
ggplot(sim1, aes(x, y)) +
  geom_point(size = 2, colour = "grey30") +
  geom_abline(intercept = best$par[1], slope = best$par[2])
```

![](23-pres_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;

---

No te preocupes demasiado acerca de los detalles de c√≥mo funciona optim(). La intuici√≥n es lo importante. Si tienes una funci√≥n que define la m√≠nima distancia entre un modelo y un conjunto de datos, un algoritmo que pueda minimizar la distancia modificando los par√°metros del modelo te permitir√° encontrar el mejor modelo. Lo interesante de este enfoque es que funciona con cualquier familia de modelos respecto de la cual se pueda escribir una ecuaci√≥n que los describa.

Existe otro enfoque que podemos usar para este modelo, debido a que es un caso especial de una familia m√°s amplia: los modelos lineales. Un modelo lineal es de la forma y = a_1 + a_2 * x_1 + a_3 * x_2 + ... + a_n * x_(n+1). Este modelo simple es equivalente a un modelo lineal generalizado en el que n tiene valor 2 y x_1 es x. R cuenta con una herramienta dise√±ada especialmente para ajustar modelos lineales llamada lm(). lm() tiene un modo especial de especificar la familia del modelo: las f√≥rmulas. Las f√≥rmulas son similares a y ~ x, que lm() traducir√° a una funci√≥n de la forma y = a_1 + a_2 * x. Podemos ajustar el modelo y mirar la salida:

---
# Usando la funci√≥n lm


```r
sim1_mod &lt;- lm(y ~ x, data = sim1)
coef(sim1_mod)
```

```
## (Intercept)           x 
##    4.220822    2.051533
```

---

## Visualizando modelos


```r
grid &lt;- sim1 %&gt;%
  data_grid(x)
grid
```

```
## # A tibble: 10 x 1
##        x
##    &lt;int&gt;
##  1     1
##  2     2
##  3     3
##  4     4
##  5     5
##  6     6
##  7     7
##  8     8
##  9     9
## 10    10
```


---


```r
grid &lt;- grid %&gt;%
  add_predictions(sim1_mod)
grid
```

```
## # A tibble: 10 x 2
##        x  pred
##    &lt;int&gt; &lt;dbl&gt;
##  1     1  6.27
##  2     2  8.32
##  3     3 10.4 
##  4     4 12.4 
##  5     5 14.5 
##  6     6 16.5 
##  7     7 18.6 
##  8     8 20.6 
##  9     9 22.7 
## 10    10 24.7
```

---
A continuaci√≥n, graficamos las predicciones. Te preguntar√°s acerca de todo este trabajo adicional en comparaci√≥n a usar geom_abline(). Pero la ventaja de este enfoque es que funciona con cualquier modelo en R, desde los m√°s simples a los m√°s complejos. La √∫nica limitante son tus habilidades de visualizaci√≥n. Para m√°s ideas respecto de como visualizar modelos complejos, puedes consultar http://vita.had.co.nz/papers/model-vis.html.


```r
ggplot(sim1, aes(x)) +
  geom_point(aes(y = y)) +
  geom_line(aes(y = pred), data = grid, colour = "red", size = 1)
```

![](23-pres_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

---

background-image: url(img/fondo-madera.png)
background-size: cover
class: center, middle

## Residuos

## Las predicciones te informan de los patrones que el modelo captura y los residuos te dicen lo que el modelo ignora. 
## Los residuos son las distancias entre lo observado y los valores predichos que calculamos anteriormente.



---

## add_residuals()
Notar que usamos __el data frame original y no no una grilla manufacturada.__¬¥ Esto es porque para calcular los residuos se necesitan los valores de ‚Äúy‚Äù.



```r
sim1 &lt;- sim1 %&gt;%
  add_residuals(sim1_mod)
sim1
```

```
## # A tibble: 30 x 3
##        x     y    resid
##    &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1     1  4.20 -2.07   
##  2     1  7.51  1.24   
##  3     1  2.13 -4.15   
##  4     2  8.99  0.665  
##  5     2 10.2   1.92   
##  6     2 11.3   2.97   
##  7     3  7.36 -3.02   
##  8     3 10.5   0.130  
##  9     3 10.5   0.136  
## 10     4 12.4   0.00763
## # ‚Ä¶ with 20 more rows
```

---
## Pol√≠gono de frecuencias

Existen diferentes formas de entender qu√© nos dicen los residuos respecto del modelo. Una forma es dibujar un pol√≠gono de frecuencia que nos ayude a entender c√≥mo se propagan los residuos:


```r
ggplot(sim1, aes(resid)) +
  geom_freqpoly(binwidth = 0.5)
```

![](23-pres_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;

---

Esto ayuda a calibrar la __calidad del modelo:__ ¬øqu√© tan lejos se encuentran las predicciones de los valores observados? Nota que el promedio del residuo es siempre cero.

A menudo vas a querer crear gr√°ficos usando los residuos en lugar del predictor original. Ver√°s mucho de eso en el cap√≠tulo siguiente:


```r
ggplot(sim1, aes(x, resid)) +
  geom_ref_line(h = 0) +
  geom_point()
```

![](23-pres_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;


---
background-image: url(img/fondo-madera.png)
background-size: cover
class: center, middle

## Esto parece ser ruido aleatorio, lo que sugiere que el modelo ha hecho un buen trabajo capturando los patrones del conjunto de datos.

---
background-image: url(img/text-msg.png)
background-size: cover
class: center, middle

## F√≥rmulas y familias de modelos

---


Ya habr√°s visto f√≥rmulas anteriormente cuando usamos facet_wrap() y facet_grid(). En R, las f√≥rmulas proveen un modo general de obtener ‚Äúcomportamientos especiales‚Äù. En lugar de evaluar los valores de las variables directamente, se capturan los valores para que sean interpretados por una funci√≥n.

La mayor√≠a de los las funciones de modelado en R usan una conversi√≥n est√°ndar para las f√≥rmulas y las funciones. Ya habr√°s visto una conversi√≥n simple y ~ x que se convierte en y = a_1 + a_2 * x. Si quieres ver lo que hace R, puedes usar la funci√≥n model_matrix(). Esta toma un data frame y una f√≥rmula para entregar un tibble que define la ecuaci√≥n del modelo: cada columna en la salida est√° asociada con un coeficiente del modelo, la funci√≥n es siempre y = a_1 * salida_1 + a_2 * salida_2. Para el caso simple y ~ x1 esto nos muestra algo interesante:

---


```r
df &lt;- tribble(
  ~y, ~x1, ~x2,
  4, 2, 5,
  5, 1, 6
)
model_matrix(df, y ~ x1)
```

```
## # A tibble: 2 x 2
##   `(Intercept)`    x1
##           &lt;dbl&gt; &lt;dbl&gt;
## 1             1     2
## 2             1     1
```

---

La forma en que R agrega el intercepto (u ordenada al origen) al modelo es mediante una columna de unos. Por defecto, R siempre agregar√° esta columna. Si no quieres esto, necesitas excluirla expl√≠citamente usando -1:


```r
model_matrix(df, y ~ x1 - 1)
```

```
## # A tibble: 2 x 1
##      x1
##   &lt;dbl&gt;
## 1     2
## 2     1
```

La matriz del modelo crece de manera nada sorprendente si incluyes m√°s variables al modelo:


```r
model_matrix(df, y ~ x1 + x2)
```

```
## # A tibble: 2 x 3
##   `(Intercept)`    x1    x2
##           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1             1     2     5
## 2             1     1     6
```



---
Las siguientes secciones detallan c√≥mo esta notaci√≥n de f√≥rmulas funciona con variables categ√≥ricas, interacciones y transformaciones.



---
background-image: url(img/text-msg.png)
background-size: cover
class: center, middle


# Variables categ√≥ricas


---


## Variables categ√≥ricas


Generar una funci√≥n a partir de una f√≥rmula es directo cuando el predictor es una variable continua, pero las cosas son m√°s complicadas cuando el predictor es una variable categ√≥rica. Imagina que tienes una f√≥rmula como y ~ sexo, donde el sexo puede ser hombre o mujer. No tiene sentido convertir a una f√≥rmula del tipo y = x_0 + x_1 * sexo debido a que sexo no es un n√∫mero - ¬°no se puede multiplicar! En su lugar, lo que R hace es convertir a y = x_0 + x_1 * sexo_hombre donde sexo_hombre tiene valor 1 si sexo corresponde a hombre y cero a mujer:

---


```r
df &lt;- tribble(
  ~genero, ~respuesta,
  "masculino", 1,
  "femenino", 2,
  "masculino", 1
)
model_matrix(df, respuesta ~ genero)
```

```
## # A tibble: 3 x 2
##   `(Intercept)` generomasculino
##           &lt;dbl&gt;           &lt;dbl&gt;
## 1             1               1
## 2             1               0
## 3             1               1
```

---

Quiz√° te preguntes por qu√© R no crea la columna generofemenino. El problema es que eso crear√≠a una columna perfectamente predecible a partir de las otras columnas (es decir, generofemenino = 1 - generomasculino). Desafortunadamete los detalles exactos de por qu√© esto es un problema van m√°s all√° del alcance del libro, pero b√°sicamente crea una familia de modelos que es muy flexible y genera infinitos modelos igualmente cercanos a los datos.

Afortunadamente, sin embargo, si te enfocas en visualizar las predicciones no necesitas preocuparte de la parametrizaci√≥n exacta. Veamos algunos datos y modelos para hacer algo concreto. Aqu√≠ est√° el dataset sim2 de modelr:

---


```r
ggplot(sim2) +
  geom_point(aes(x, y))
```

![](23-pres_files/figure-html/unnamed-chunk-25-1.png)&lt;!-- --&gt;

---

Podemos ajustar un modelo a esto y generar predicciones:


```r
mod2 &lt;- lm(y ~ x, data = sim2)

grid &lt;- sim2 %&gt;%
  data_grid(x) %&gt;%
  add_predictions(mod2)
grid
```

```
## # A tibble: 4 x 2
##   x      pred
##   &lt;chr&gt; &lt;dbl&gt;
## 1 a      1.15
## 2 b      8.12
## 3 c      6.13
## 4 d      1.91
```

---

Efectivamente, un modelo con una variable x categ√≥rica va a predecir el valor medio para cada categor√≠a. (¬øPor qu√©? porque la media minimiza la ra√≠z de la distancia media cuadr√°tica.) Es f√°cil de ver si superponemos la predicci√≥n sobre los datos originales:


```r
ggplot(sim2, aes(x)) +
  geom_point(aes(y = y)) +
  geom_point(data = grid, aes(y = pred), colour = "red", size = 4)
```

![](23-pres_files/figure-html/unnamed-chunk-27-1.png)&lt;!-- --&gt;

---

No es posible hacer predicciones sobre niveles no observados. A veces har√°s esto por accidente, por lo que es bueno reconocer el siguiente mensaje de error:


```r
tibble(x = "e") %&gt;%
  add_predictions(mod2)
```

---

background-image: url(img/text-msg.png)
background-size: cover
class: center, middle


# Interacciones 
## (continuas y categ√≥ricas)

---


#### ¬øQu√© ocurre si combinas una variable continua y una categ√≥rica? sim3 contiene un predictor categ√≥rico y otro predictor continuo. Podemos visualizarlos con un gr√°fico simple:


```r
ggplot(sim3, aes(x1, y)) +
  geom_point(aes(colour = x2))
```

![](23-pres_files/figure-html/unnamed-chunk-29-1.png)&lt;!-- --&gt;

---

Existen dos posibles modelos que se pueden ajustar a estos datos:


```r
mod1 &lt;- lm(y ~ x1 + x2, data = sim3)
mod2 &lt;- lm(y ~ x1 * x2, data = sim3)
```

__Cuando agregas variables con + el modelo va a estimar cada efecto independientemente de los dem√°s. Es posible agregar al ajuste lo que se conoce como interacci√≥n usando * . __

Por ejemplo, y ~ x1 * x2 se traduce en y = a_0 + a_1 * x_1 + a_2 * x_2 + a_12 * x_1 * x_2. Observa que si usas *, tanto el efecto interacci√≥n como los efectos individuales se incluyen en el modelo.

Para visualizar estos modelos necesitamos dos nuevos trucos:

1. Tenemos dos predictores, por lo que necesitamos pasar ambas variables a __data_grid()__. Esto encontrar√° todos los valores √∫nicos de x1 y x2 y luego generar√° todas las combinaciones,

2. Para generar predicciones de ambos modelos simult√°neamente, podemos usar __gather_predictions()__ que incorpora cada predicci√≥n como una fila. El complemento de __gather_predictions()__ es __spread_predictions()__ que incluye cada predicci√≥n en una nueva columna.

---

Esto combinado nos da:


```r
grid &lt;- sim3 %&gt;%
  data_grid(x1, x2) %&gt;%
  gather_predictions(mod1, mod2)
grid
```

```
## # A tibble: 80 x 4
##    model    x1 x2     pred
##    &lt;chr&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt;
##  1 mod1      1 a      1.67
##  2 mod1      1 b      4.56
##  3 mod1      1 c      6.48
##  4 mod1      1 d      4.03
##  5 mod1      2 a      1.48
##  6 mod1      2 b      4.37
##  7 mod1      2 c      6.28
##  8 mod1      2 d      3.84
##  9 mod1      3 a      1.28
## 10 mod1      3 b      4.17
## # ‚Ä¶ with 70 more rows
```

---

Podemos visualizar los resultados de ambos modelos en un gr√°fico usando separando en facetas:


```r
ggplot(sim3, aes(x1, y, colour = x2)) +
  geom_point() +
  geom_line(data = grid, aes(y = pred)) +
  facet_wrap(~model)
```

![](23-pres_files/figure-html/unnamed-chunk-32-1.png)&lt;!-- --&gt;

---
background-image: url(img/fondo-madera.png)
background-size: cover
class: center, middle

## Modelo con (+): misma pendiente pero distinta ordenada al origen.
## Modelo con (*): distinta pendiente y distinta ordenada al origen.

## ¬øQu√© modelo es el m√°s adecuado? Miramos los residuos. 

---


```r
sim3 &lt;- sim3 %&gt;%
  gather_residuals(mod1, mod2)

ggplot(sim3, aes(x1, resid, colour = x2)) +
  geom_point() +
  facet_grid(model ~ x2)
```

![](23-pres_files/figure-html/unnamed-chunk-33-1.png)&lt;!-- --&gt;
  
---

background-image: url(img/fondo-madera.png)
background-size: cover
class: center, middle

## Conclusi√≥n

## Residuos de mod1 tienen patrones ignorados en b, y un poco menos ignorados en c y d. 
## Residuos de mod2, un patr√≥n poco obvio
## ¬øExiste una forma precisa de determinar si mod1 o mod2 es mejor? S√≠, pero no la trataremos. 
## Nos interesa evaluar cualitativamente si el modelo ha capturado los patrones que nos interesan.


---

background-image: url(img/text-msg.png)
background-size: cover
class: center, middle


# Valores faltantes

---

## Valores faltantes


Los valores faltantes obviamente no proporcionan informaci√≥n respecto de la relaci√≥n entre las variables, por lo que modelar funciones va a eliminar todas las filas con valores faltantes. R por defecto lo hace de forma silenciosa, pero options(na.action = na.warn) (ejecutado en los prerrequisitos) asegura que la salida incluya una advertencia.


```r
df &lt;- tribble(
  ~x, ~y,
  1, 2.2,
  2, NA,
  3, 3.5,
  4, 8.3,
  NA, 10
)

mod &lt;- lm(y ~ x, data = df)
```

```
## Warning: Dropping 2 rows with missing values
```

---

Para suprimir los mensajes de advertencia, incluye na.action = na.exclude:


```r
mod &lt;- lm(y ~ x, data = df, na.action = na.exclude)
```

Siempre puedes consultar cu√°ntas observaciones se usaron con nobs():


```r
nobs(mod)
```

```
## [1] 3
```

---
background-image: url(img/text-msg.png)
background-size: cover
class: center, middle


# Otras familias de modelos

---
#Otras familias de modelos(1)

Este cap√≠tulo se centr√≥ de forma exclusiva en la familia de modelos lineales, la cual asume una relaci√≥n de la forma y = a_1 * x1 + a_2 * x2 + ... + a_n * xn. Adem√°s, los modelos lineales asumen que los residuos siguen una distribuci√≥n normal, algo de lo que no hemos hablado. Existe un amplio conjunto de familias de modelos que extienden la familia de modelos lineales de varias formas interesantes. Algunos son:

* Modelos lineales generalizados, es decir, stats::glm(). Los modelos lineales asumen que la respuesta es una variable continua y que el error sigue una distribuci√≥n normal. Los modelos lineales generalizados extienden los modelos lineales para incluir respuestas no continuas (es decir, datos binarios o conteos). Definen una distancia m√©trica basada en la idea estad√≠stica de verosimilitud.

* Modelos generalizados aditivos, es decir, mgcv::gam(), extienden los modelos lineales generalizados para incorporar funciones suaves arbitrarias. Esto significa que puedes escribir una f√≥rmula del tipo y ~ s(x) que se transforma en una ecuaci√≥n de la forma y = f(x) y dejar que gam() estime la funci√≥n (sujeto a algunas restricciones de suavidad para que el problema sea manejable).



---
#Otras familias de modelos(2)

* Modelos lineales penalizados, es decir, glmnet::glmnet(), incorporan un t√©rmino de penalizaci√≥n a la distancia y as√≠ penalizan modelos complejos (definidos por la distancia entre el vector de par√°metros y el origen). Esto tiende a entregar modelos que generalizan mejor respecto de nuevos conjuntos de datos para la misma poblaci√≥n.

* Modelos lineales robustos, es decir, MASS:rlm(), modifican la distancia para restar importancia a los puntos que quedan muy alejados. Esto resulta en modelos menos sensibles a valores extremos, con el inconveniente de que no son muy buenos cuando no hay valores extremos.
* √Årboles, es decir, rpart::rpart(), atacan un problema de un modo totalmente distinto a los modelos lineales. Ajustan un modelo constante por partes, dividiendo los datos en partes progresivamente m√°s y m√°s peque√±as. Los √°rboles no son tremendamente efectivos por s√≠ solos, pero son muy poderosos cuando se usan en modelos agregados como bosques aleatorios, del ingl√©s random forests), (es decir, randomForest::randomForest()) o m√°quinas aceleradoras de gradiente, del ingl√©s gradient boosting machines (es decir, xgboost::xgboost.).
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
